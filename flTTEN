from pyspark.sql import SparkSession
from pyspark.sql.functions import col, regexp_extract, split

# Create SparkSession
spark = SparkSession.builder \
    .appName("Explode Example") \
    .getOrCreate()

# Sample DataFrame
data = [("{123:[abc|12|A]}",),
        ("{456:[abc|12|A]}",)]

df = spark.createDataFrame(data, ["input"])

# Extracting values using regular expressions
df = df.withColumn("key", regexp_extract(col("input"), r'{(\d+):', 1))
df = df.withColumn("values", regexp_extract(col("input"), r':\[([^\]]+)\]', 1))

# Splitting values into separate columns
df = df.withColumn("values", split(col("values"), "\|"))
df = df.select(col("key").alias("ID"), 
               col("values").getItem(0).alias("Value1"), 
               col("values").getItem(1).alias("Value2"), 
               col("values").getItem(2).alias("Value3"))

df.show()
