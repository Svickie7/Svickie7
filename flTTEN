from pyspark.sql import SparkSession
from pyspark.sql.functions import col, expr, from_json
from pyspark.sql.types import StructType, StringType

# Create SparkSession
spark = SparkSession.builder \
    .appName("Dynamic Deep Flatten JSON") \
    .getOrCreate()

# Sample DataFrame with JSON data
data = [
    (1001, '{"id": "0001", "type": "donut", "name": "Cake", "ppu": 0.55, "batters": {"batter": [{"id": "1001", "type": "Regular"}, {"id": "1002", "type": "Chocolate"}, {"id": "1003", "type": "Blueberry"}, {"id": "1004", "type": "Devil\'s Food"}]}, "topping": [{"id": "5001", "type": "None"}, {"id": "5002", "type": "Glazed"}, {"id": "5005", "type": "Sugar"}, {"id": "5007", "type": "Powdered Sugar"}, {"id": "5006", "type": "Chocolate with Sprinkles"}, {"id": "5003", "type": "Chocolate"}, {"id": "5004", "type": "Maple"}]}'),
    (1002, '{"id": "0001", "type": "donut", "name": "Cake", "ppu": 0.55, "batters": {"batter": [{"id": "1001", "type": "Regular"}, {"id": "1002", "type": "Chocolate"}, {"id": "1003", "type": "Blueberry"}, {"id": "1004", "type": "Devil\'s Food"}]}, "topping": [{"id": "5001", "type": "None"}, {"id": "5002", "type": "Glazed"}, {"id": "5005", "type": "Sugar"}, {"id": "5007", "type": "Powdered Sugar"}, {"id": "5006", "type": "Chocolate with Sprinkles"}, {"id": "5003", "type": "Chocolate"}, {"id": "5004", "type": "Maple"}]}')
]

# Define schema dynamically
schema = StructType() \
    .add("product_id", StringType(), False) \
    .add("json_data", StringType(), False)

# Create DataFrame
df = spark.createDataFrame(data, schema=schema)

# Function to recursively flatten JSON data
def flatten_json(df, prefix=""):
    flat_cols = []
    for col_name in df.schema.names:
        if isinstance(df.schema[col_name].dataType, StructType):
            if prefix == "":
                flat_cols += flatten_json(df.selectExpr(f"{col_name}.*"), f"{col_name}.")
            else:
                flat_cols += flatten_json(df.selectExpr(f"{prefix}{col_name}.*"), f"{prefix}{col_name}.")
        else:
            flat_cols.append(expr(f"{prefix}{col_name} as {prefix.replace('.', '_')}{col_name.replace('.', '_')}"))
    return flat_cols

# Flatten JSON data deeply and dynamically
flattened_df = df.withColumn("json_data", from_json(col("json_data"), schema=StructType())) \
    .selectExpr("product_id", "json_data.*") \
    .select(flatten_json(col("*")))

# Show the dynamically flattened DataFrame
flattened_df.show(truncate=False)

# Stop SparkSession
spark.stop()
